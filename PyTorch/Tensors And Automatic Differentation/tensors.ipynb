{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing tensors with other data-types and other devices (CPU or CUDA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cuda\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tensor1f = torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float32, device=\"cuda\") #cpu is default\n",
    "print(\"Device is:\",device)\n",
    "print(tensor1f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing tensors for automatic differentiation,\n",
    "\n",
    "To see what is auto-grad check https://arxiv.org/abs/1811.05031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n",
      "torch.float32\n",
      "cuda:0\n",
      "torch.Size([2, 3])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "tensor1fad = torch.tensor([[1,2,3],[4,5,6]],dtype=torch.float32, device=\"cuda\",requires_grad = True) #cpu is default\n",
    "print(tensor1f)\n",
    "print(tensor1fad.dtype)\n",
    "print(tensor1fad.device) ## zero is first gpu, if you have one gpu it is always zero.\n",
    "print(tensor1fad.shape)\n",
    "print(tensor1fad.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Initialization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.9528e+16, 3.0889e-41, 5.6052e-45],\n",
      "        [0.0000e+00,        nan, 0.0000e+00],\n",
      "        [1.1578e+27, 4.1666e+34, 5.3853e+08]])\n"
     ]
    }
   ],
   "source": [
    "tensor2 = torch.empty(size=(3,3)) #values will be whatever in the memory at that moment\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "tensor3 = torch.zeros((3,3))\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2400, 0.9275, 0.5815],\n",
      "        [0.8824, 0.3535, 0.5638],\n",
      "        [0.7510, 0.7501, 0.3892]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor4 = torch.rand((3,3)) # from uniform distribution in the interval 0 and 1\n",
    "print(tensor4)\n",
    "print(tensor4.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor5 = torch.ones((2,2))\n",
    "print(tensor5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor6 = torch.eye(5,5) # initializes identity matrix\n",
    "print(tensor6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor7 = torch.arange(start=0,end=5,step=1)\n",
    "print(tensor7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "tensor8 = torch.linspace(start=0.1, end=1, steps=10)\n",
    "print(tensor8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2215,  0.1040,  1.1097, -0.5321, -2.1323]])\n"
     ]
    }
   ],
   "source": [
    "tensor9 = torch.empty(size=(1,5)).normal_(mean = 0, std = 1)\n",
    "print(tensor9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0810, 0.8847, 0.4055, 0.5601, 0.7550]])\n"
     ]
    }
   ],
   "source": [
    "tensor10 = torch.empty(size=(1,5)).uniform_(0,1)\n",
    "print(tensor10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9528e+16,        nan, 5.3853e+08])\n"
     ]
    }
   ],
   "source": [
    "tensor11 = torch.diag(tensor2)\n",
    "print(tensor11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "torch.int64\n",
      "tensor([0, 1, 2, 3], dtype=torch.int16)\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tensor12 = torch.arange(4)\n",
    "print(tensor12)\n",
    "print(tensor12.dtype)\n",
    "print(tensor12.short()) # creates torch.int16\n",
    "print(tensor12.long()) # creates torch.int64\n",
    "print(tensor12.half()) # creates torch.float16\n",
    "print(tensor12.float()) #creates torch.float32\n",
    "print(tensor12.double()) #creates torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array to Tensor Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.zeros((5,5))\n",
    "tensor13 = torch.from_numpy(arr1) # numpy array to torch tensor\n",
    "arr1_back = tensor13.numpy() # torch tensor to numpy array\n",
    "# WARNING: there can be some numerical round-off errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Maths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor14 = torch.tensor([1,2,3])\n",
    "tensor15 = torch.tensor([9,8,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "tensor16 = torch.add(tensor14, tensor15)\n",
    "print(tensor16)\n",
    "# or just tensor16 = tensor14 + tensor15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-8, -6, -4])\n"
     ]
    }
   ],
   "source": [
    "tensor17 = tensor14 - tensor15\n",
    "print(tensor17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor18 = tensor15 / tensor14\n",
    "print(tensor18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponentations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([81, 16,  4])\n"
     ]
    }
   ],
   "source": [
    "tensor20 = tensor18 ** 2\n",
    "print(tensor20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparsions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1], dtype=torch.uint8)\n",
      "tensor([1, 1, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(tensor14 > 0)\n",
    "print(tensor20 >= 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Multiplications:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9813, 0.9940, 1.6766, 0.7648],\n",
      "        [1.5068, 1.2899, 2.4730, 1.8349]])\n"
     ]
    }
   ],
   "source": [
    "tensor21 = torch.rand((2,5))\n",
    "tensor22 = torch.rand((5,4))\n",
    "tensor23 = torch.mm(tensor21, tensor22) # 2 x 4\n",
    "print(tensor23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise Multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9, 16, 21])\n"
     ]
    }
   ],
   "source": [
    "tensor24 = tensor14 * tensor15\n",
    "print(tensor24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot Product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(46)\n"
     ]
    }
   ],
   "source": [
    "tensor25 = torch.dot(tensor14,tensor15)\n",
    "print(tensor25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Matrix Multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.4860, 4.1094, 5.8712,  ..., 4.8428, 5.3126, 5.4184],\n",
      "         [5.2873, 4.3785, 6.2349,  ..., 6.2649, 5.9693, 5.9115],\n",
      "         [4.6183, 4.4562, 5.1974,  ..., 5.3956, 4.7370, 4.7624],\n",
      "         ...,\n",
      "         [4.5693, 3.6962, 4.7715,  ..., 4.5770, 5.9074, 4.2569],\n",
      "         [4.9908, 4.0985, 5.8262,  ..., 6.1090, 5.8616, 5.6223],\n",
      "         [6.0819, 5.4564, 7.5043,  ..., 6.1924, 6.8475, 6.3794]],\n",
      "\n",
      "        [[5.2088, 6.3306, 5.0007,  ..., 5.7079, 6.3852, 6.4534],\n",
      "         [4.6208, 5.7491, 3.4608,  ..., 4.4189, 5.3284, 5.4780],\n",
      "         [4.3648, 5.2081, 4.1212,  ..., 4.5857, 4.6831, 5.5319],\n",
      "         ...,\n",
      "         [5.2402, 6.8368, 6.1730,  ..., 5.7485, 6.3287, 7.0082],\n",
      "         [4.6092, 5.2739, 4.0838,  ..., 4.5208, 5.0323, 5.6456],\n",
      "         [4.8233, 5.7883, 4.5134,  ..., 5.2798, 5.4929, 5.7767]],\n",
      "\n",
      "        [[5.9443, 6.0276, 6.4823,  ..., 6.2598, 5.2528, 5.9868],\n",
      "         [5.1042, 4.7751, 5.1891,  ..., 4.4834, 4.2521, 5.5360],\n",
      "         [6.5357, 6.4827, 6.0426,  ..., 5.9891, 5.5619, 5.8705],\n",
      "         ...,\n",
      "         [5.3218, 5.7839, 5.0054,  ..., 5.8662, 4.9497, 4.8744],\n",
      "         [6.7089, 6.5925, 7.7016,  ..., 6.5264, 6.0948, 6.3731],\n",
      "         [5.2947, 5.4053, 5.5805,  ..., 5.1162, 4.6891, 4.6390]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[6.7749, 5.7903, 5.3204,  ..., 5.7338, 5.4645, 5.0471],\n",
      "         [6.1367, 4.5002, 4.4129,  ..., 4.2399, 5.4271, 5.0167],\n",
      "         [4.6019, 2.7846, 3.2827,  ..., 3.6247, 4.2715, 3.4601],\n",
      "         ...,\n",
      "         [5.9382, 4.5034, 4.0900,  ..., 4.3886, 5.3180, 4.4507],\n",
      "         [5.5509, 4.8331, 4.8848,  ..., 5.0966, 5.1177, 5.2778],\n",
      "         [5.0539, 3.9972, 4.8120,  ..., 4.4862, 4.7728, 4.5025]],\n",
      "\n",
      "        [[6.4037, 5.6748, 5.7080,  ..., 5.6729, 6.3983, 4.6838],\n",
      "         [3.3323, 3.1520, 3.6382,  ..., 3.6170, 4.0399, 2.9233],\n",
      "         [5.1484, 4.6565, 5.3552,  ..., 5.4791, 6.0827, 4.0854],\n",
      "         ...,\n",
      "         [5.3194, 4.1981, 4.4082,  ..., 4.6246, 5.2557, 3.2823],\n",
      "         [5.6358, 4.5198, 4.6796,  ..., 5.4673, 5.8259, 3.7419],\n",
      "         [6.4062, 5.3064, 6.2088,  ..., 5.8036, 6.8179, 4.4117]],\n",
      "\n",
      "        [[5.6831, 6.3330, 6.2398,  ..., 5.4253, 5.6678, 5.9812],\n",
      "         [4.7490, 4.5975, 4.9947,  ..., 3.5737, 4.1482, 3.7741],\n",
      "         [6.3730, 5.3284, 5.1258,  ..., 4.8080, 4.7729, 4.7035],\n",
      "         ...,\n",
      "         [6.3285, 6.4305, 6.6985,  ..., 5.0277, 5.9133, 5.6889],\n",
      "         [4.4546, 4.6667, 4.4183,  ..., 3.5787, 4.2542, 4.0857],\n",
      "         [3.8081, 4.8662, 4.1451,  ..., 3.2875, 3.5334, 3.8457]]])\n"
     ]
    }
   ],
   "source": [
    "batch = 32\n",
    "n = 10\n",
    "m = 20\n",
    "p = 30\n",
    "tensor26 = torch.rand((batch,n,m))\n",
    "tensor27 = torch.rand((batch,m,p))\n",
    "tensor28 = torch.bmm(tensor26,tensor27)\n",
    "#shape = (batch, n, p)\n",
    "print(tensor28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3146, 0.5835, 0.5399, 0.0835, 0.4572],\n",
      "        [0.2126, 0.1363, 0.7588, 0.4865, 0.0232],\n",
      "        [0.4498, 0.5166, 0.6925, 0.9647, 0.7111],\n",
      "        [0.2460, 0.3827, 0.6107, 0.8897, 0.8874],\n",
      "        [0.0862, 0.5934, 0.5778, 0.6017, 0.6110]])\n",
      "tensor([[0.2452, 0.0699, 0.6109, 0.5753, 0.8402]])\n",
      "tensor([[ 6.9374e-02,  5.1363e-01, -7.0942e-02, -4.9179e-01, -3.8300e-01],\n",
      "        [-3.2614e-02,  6.6469e-02,  1.4791e-01, -8.8753e-02, -8.1697e-01],\n",
      "        [ 2.0457e-01,  4.4674e-01,  8.1596e-02,  3.8937e-01, -1.2913e-01],\n",
      "        [ 8.1909e-04,  3.1283e-01, -1.4323e-04,  3.1441e-01,  4.7253e-02],\n",
      "        [-1.5903e-01,  5.2354e-01, -3.3112e-02,  2.6462e-02, -2.2919e-01]])\n",
      "tensor([[0.7531, 0.9631, 0.6863, 0.2397, 0.5181],\n",
      "        [0.6841, 0.8700, 0.8448, 0.6607, 0.0424],\n",
      "        [0.8221, 0.9549, 0.7989, 0.9795, 0.7509],\n",
      "        [0.7090, 0.9351, 0.7399, 0.9350, 0.9045],\n",
      "        [0.5482, 0.9642, 0.7152, 0.7466, 0.6611]])\n"
     ]
    }
   ],
   "source": [
    "tensor29 = torch.rand((5,5))\n",
    "tensor30 = torch.rand((1,5)) #is like each row is identical to each other\n",
    "tensor31 = tensor29 - tensor30\n",
    "tensor32 = tensor29 ** tensor30\n",
    "print(tensor29)\n",
    "print(tensor30)\n",
    "print(tensor31)\n",
    "print(tensor32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Type of Operations on Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1288, 0.1928, 0.3714, 0.1745],\n",
      "        [0.9756, 0.4671, 0.6382, 0.4853],\n",
      "        [0.6258, 0.3075, 0.1725, 0.4017],\n",
      "        [0.1607, 0.6643, 0.5309, 0.3876]])\n",
      "tensor([1.8909, 1.6316, 1.7130, 1.4490])\n",
      "tensor([0.8676, 2.5661, 1.5074, 1.7434])\n"
     ]
    }
   ],
   "source": [
    "tensor33 = torch.rand((4,4))\n",
    "tensor34 = torch.sum(tensor33,dim=0)\n",
    "tensor35 = torch.sum(tensor33,dim=1)\n",
    "print(tensor33)\n",
    "print(tensor34)\n",
    "print(tensor35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1288, 0.1928, 0.3714, 0.1745],\n",
      "        [0.9756, 0.4671, 0.6382, 0.4853],\n",
      "        [0.6258, 0.3075, 0.1725, 0.4017],\n",
      "        [0.1607, 0.6643, 0.5309, 0.3876]])\n",
      "Values1, indices1 (dim0: columns): tensor([0.9756, 0.6643, 0.6382, 0.4853]) and tensor([1, 3, 1, 1])\n",
      "Values2, indices2 (dim1: rows): tensor([0.3714, 0.9756, 0.6258, 0.6643]) and tensor([2, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "values1, indices1 = torch.max(tensor33,dim=0) #tensor33.max(dim=0)\n",
    "values2, indices2 = torch.max(tensor33,dim=1)\n",
    "print(tensor33)\n",
    "print(\"Values1, indices1 (dim0: columns): {} and {}\".format(values1,indices1))\n",
    "print(\"Values2, indices2 (dim1: rows): {} and {}\".format(values2,indices2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3712, -0.3072, -0.1286, -0.3255],\n",
      "        [ 0.4756, -0.0329,  0.1382, -0.0147],\n",
      "        [ 0.1258, -0.1925, -0.3275, -0.0983],\n",
      "        [-0.3393,  0.1643,  0.0309, -0.1124]])\n",
      "tensor([[0.3712, 0.3072, 0.1286, 0.3255],\n",
      "        [0.4756, 0.0329, 0.1382, 0.0147],\n",
      "        [0.1258, 0.1925, 0.3275, 0.0983],\n",
      "        [0.3393, 0.1643, 0.0309, 0.1124]])\n"
     ]
    }
   ],
   "source": [
    "tensor36 = tensor33 - 0.50\n",
    "print(tensor36)\n",
    "tensor37 = torch.abs(tensor36)\n",
    "print(tensor37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 1, 1])\n",
      "tensor([0, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "tensor38 = torch.argmax(tensor33,dim=0) #actually it returns torch.max's second return argument\n",
    "tensor39 = torch.argmin(tensor33,dim=1)\n",
    "print(tensor38)\n",
    "print(tensor39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4727, 0.4079, 0.4283, 0.3623])\n"
     ]
    }
   ],
   "source": [
    "tensor40 = torch.mean(tensor33.float(),dim=0) #input has to be float\n",
    "print(tensor40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1288, 0.1928, 0.1725, 0.1745],\n",
      "        [0.1607, 0.3075, 0.3714, 0.3876],\n",
      "        [0.6258, 0.4671, 0.5309, 0.4017],\n",
      "        [0.9756, 0.6643, 0.6382, 0.4853]])\n"
     ]
    }
   ],
   "source": [
    "sorted_tensor33, indices3 = torch.sort(tensor33, dim=0, descending=False)\n",
    "print(sorted_tensor33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10.],\n",
      "        [10., 10., 10., 10.]])\n"
     ]
    }
   ],
   "source": [
    "tensor41 = torch.clamp(tensor33, min=10)\n",
    "#check all elements of tensor33 and if it is less than 10, gonna set to zero\n",
    "print(tensor41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n",
      "torch.Size([10])\n",
      "tensor([0.0836, 0.4753, 0.7446, 0.5352, 0.5841, 0.4024, 0.3516, 0.3523, 0.5565,\n",
      "        0.8405])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "features = 25\n",
    "tensor42 = torch.rand((batch_size,features))\n",
    "print(tensor42[0,:].shape)\n",
    "print(tensor42[:,0].shape)\n",
    "print(tensor42[2,0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fancy Indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([1, 3, 7])\n"
     ]
    }
   ],
   "source": [
    "tensor43 = torch.arange(10)\n",
    "print(tensor43)\n",
    "indices = [1,3,7]\n",
    "print(tensor43[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "print(tensor43[(tensor43 <2) | (tensor43 > 8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "print(tensor43[tensor43.remainder(2) == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  4,  9, 16, 25,  6,  7,  8,  9])\n"
     ]
    }
   ],
   "source": [
    "print(tensor43.where(tensor43 > 5, tensor43**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 3, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([0,0,1,2,2,3,4,4]).unique())\n",
    "#sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(tensor43.ndimension()) #number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(tensor43.numel()) #number of elements in tensor\n",
    "#it is easier to get number of elements in lower dimensions\n",
    "#but this function is useful in higher dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "tensor44 = torch.arange(9)\n",
    "tensor44_3x3 = tensor44.view(3,3)\n",
    "tensor44_3x3_1 = tensor44.reshape(3,3)\n",
    "print(tensor44)\n",
    "print(tensor44_3x3)\n",
    "print(tensor44_3x3_1)\n",
    "#reshape tries to return a view if possible, \n",
    "#otherwise copies to data to a contiguous tensor and returns the view on it. \n",
    "# view -> contiguous\n",
    "# reshape -> doesnt really matters (safe one but performance loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3, 6],\n",
      "        [1, 4, 7],\n",
      "        [2, 5, 8]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at /opt/conda/conda-bld/pytorch_1544081038057/work/aten/src/TH/generic/THTensor.cpp:213",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-e223523bdd73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor45\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor44_3x3_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#transpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor45\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# should be [0,3,6,1,4,7,2,5,8]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#jumping steps in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#now the transpose version is not a contiguous blocks of memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at /opt/conda/conda-bld/pytorch_1544081038057/work/aten/src/TH/generic/THTensor.cpp:213"
     ]
    }
   ],
   "source": [
    "tensor45 = tensor44_3x3_1.t() #transpose\n",
    "print(tensor45)\n",
    "print(tensor45.view(9)) # should be [0,3,6,1,4,7,2,5,8]\n",
    "#jumping steps in memory\n",
    "#now the transpose version is not a contiguous blocks of memory.\n",
    "#look at the error:\n",
    "#how to fiX:\n",
    "print(tensor45.contiguous().view(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9023, 0.0174, 0.0234, 0.2747, 0.4161],\n",
      "        [0.1898, 0.9965, 0.0763, 0.9456, 0.1874],\n",
      "        [0.3045, 0.6030, 0.2394, 0.0557, 0.5099],\n",
      "        [0.8243, 0.5855, 0.9251, 0.7641, 0.8823],\n",
      "        [0.9357, 0.6500, 0.9756, 0.7506, 0.3703],\n",
      "        [0.1949, 0.7359, 0.3033, 0.6607, 0.2303],\n",
      "        [0.7564, 0.8474, 0.3711, 0.1613, 0.1588],\n",
      "        [0.8532, 0.7324, 0.1657, 0.2771, 0.1029],\n",
      "        [0.1713, 0.6983, 0.2314, 0.8304, 0.7855],\n",
      "        [0.1971, 0.5955, 0.1155, 0.3583, 0.9472]])\n"
     ]
    }
   ],
   "source": [
    "tensor46 = torch.rand((5,5))\n",
    "tensor47 = torch.rand((5,5))\n",
    "tensor48 = torch.cat((tensor46,tensor47), dim=0)\n",
    "print(tensor48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9023, 0.0174, 0.0234, 0.2747, 0.4161, 0.1898, 0.9965, 0.0763, 0.9456,\n",
      "        0.1874, 0.3045, 0.6030, 0.2394, 0.0557, 0.5099, 0.8243, 0.5855, 0.9251,\n",
      "        0.7641, 0.8823, 0.9357, 0.6500, 0.9756, 0.7506, 0.3703, 0.1949, 0.7359,\n",
      "        0.3033, 0.6607, 0.2303, 0.7564, 0.8474, 0.3711, 0.1613, 0.1588, 0.8532,\n",
      "        0.7324, 0.1657, 0.2771, 0.1029, 0.1713, 0.6983, 0.2314, 0.8304, 0.7855,\n",
      "        0.1971, 0.5955, 0.1155, 0.3583, 0.9472])\n"
     ]
    }
   ],
   "source": [
    "tensor49 = tensor48.view(-1)\n",
    "print(tensor49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1183, 0.4753, 0.8155, 0.9203, 0.0240, 0.9939],\n",
      "        [0.0082, 0.6212, 0.9916, 0.8313, 0.6680, 0.2797],\n",
      "        [0.5901, 0.1485, 0.6576, 0.9793, 0.9190, 0.5203],\n",
      "        [0.3311, 0.3065, 0.2698, 0.3262, 0.6138, 0.0495],\n",
      "        [0.6868, 0.3269, 0.3556, 0.0920, 0.3055, 0.6259],\n",
      "        [0.1605, 0.5091, 0.5690, 0.3127, 0.6657, 0.3449],\n",
      "        [0.4915, 0.8223, 0.1271, 0.3587, 0.4400, 0.7278],\n",
      "        [0.2048, 0.8042, 0.4990, 0.3775, 0.6469, 0.5525],\n",
      "        [0.5193, 0.3407, 0.5706, 0.0144, 0.2177, 0.1730],\n",
      "        [0.4841, 0.9914, 0.2462, 0.8088, 0.2293, 0.4570],\n",
      "        [0.9818, 0.9922, 0.4088, 0.7719, 0.8278, 0.3224],\n",
      "        [0.4523, 0.8083, 0.4713, 0.7553, 0.3349, 0.2724],\n",
      "        [0.4558, 0.4578, 0.2966, 0.2713, 0.9666, 0.2902],\n",
      "        [0.7687, 0.6933, 0.2296, 0.0957, 0.2220, 0.9356],\n",
      "        [0.4461, 0.9775, 0.3541, 0.4098, 0.5456, 0.6858],\n",
      "        [0.1335, 0.2065, 0.6645, 0.4544, 0.4699, 0.1660]])\n",
      "tensor([[[0.1183, 0.9203],\n",
      "         [0.4753, 0.0240],\n",
      "         [0.8155, 0.9939]],\n",
      "\n",
      "        [[0.0082, 0.8313],\n",
      "         [0.6212, 0.6680],\n",
      "         [0.9916, 0.2797]],\n",
      "\n",
      "        [[0.5901, 0.9793],\n",
      "         [0.1485, 0.9190],\n",
      "         [0.6576, 0.5203]],\n",
      "\n",
      "        [[0.3311, 0.3262],\n",
      "         [0.3065, 0.6138],\n",
      "         [0.2698, 0.0495]],\n",
      "\n",
      "        [[0.6868, 0.0920],\n",
      "         [0.3269, 0.3055],\n",
      "         [0.3556, 0.6259]],\n",
      "\n",
      "        [[0.1605, 0.3127],\n",
      "         [0.5091, 0.6657],\n",
      "         [0.5690, 0.3449]],\n",
      "\n",
      "        [[0.4915, 0.3587],\n",
      "         [0.8223, 0.4400],\n",
      "         [0.1271, 0.7278]],\n",
      "\n",
      "        [[0.2048, 0.3775],\n",
      "         [0.8042, 0.6469],\n",
      "         [0.4990, 0.5525]],\n",
      "\n",
      "        [[0.5193, 0.0144],\n",
      "         [0.3407, 0.2177],\n",
      "         [0.5706, 0.1730]],\n",
      "\n",
      "        [[0.4841, 0.8088],\n",
      "         [0.9914, 0.2293],\n",
      "         [0.2462, 0.4570]],\n",
      "\n",
      "        [[0.9818, 0.7719],\n",
      "         [0.9922, 0.8278],\n",
      "         [0.4088, 0.3224]],\n",
      "\n",
      "        [[0.4523, 0.7553],\n",
      "         [0.8083, 0.3349],\n",
      "         [0.4713, 0.2724]],\n",
      "\n",
      "        [[0.4558, 0.2713],\n",
      "         [0.4578, 0.9666],\n",
      "         [0.2966, 0.2902]],\n",
      "\n",
      "        [[0.7687, 0.0957],\n",
      "         [0.6933, 0.2220],\n",
      "         [0.2296, 0.9356]],\n",
      "\n",
      "        [[0.4461, 0.4098],\n",
      "         [0.9775, 0.5456],\n",
      "         [0.3541, 0.6858]],\n",
      "\n",
      "        [[0.1335, 0.4544],\n",
      "         [0.2065, 0.4699],\n",
      "         [0.6645, 0.1660]]])\n",
      "torch.Size([16, 2, 3])\n",
      "torch.Size([16, 6])\n",
      "torch.Size([16, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "batch = 16\n",
    "tensor50 = torch.rand((batch,2,3))\n",
    "tensor51 = tensor50.view(batch,-1)\n",
    "tensor52 = tensor50.permute(0,2,1)\n",
    "print(tensor51)\n",
    "print(tensor52)\n",
    "print(tensor50.shape)\n",
    "print(tensor51.shape)\n",
    "print(tensor52.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "torch.Size([1, 10])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n",
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor53 = torch.arange(10)\n",
    "print(tensor53.unsqueeze(0))\n",
    "print(tensor53.unsqueeze(0).shape)\n",
    "print(tensor53.unsqueeze(1))\n",
    "print(tensor53.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
      "torch.Size([1, 1, 10])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "tensor54 = torch.arange(10).unsqueeze(0).unsqueeze(1)\n",
    "tensor55 = tensor54.squeeze(1).squeeze(0)\n",
    "print(tensor54)\n",
    "print(tensor54.shape)\n",
    "print(tensor55)\n",
    "print(tensor55.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch's Automatic Differentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://openreview.net/pdf?id=BJJsrmfCZ\n",
    "\n",
    "Automatic Differentiation is a building block of not only PyTorch, but every DL library out there. In my opinion, PyTorch's automatic differentiation engine, called Autograd is a brilliant tool to understand how automatic differentiation works. This will not only help you understand PyTorch better, but also other DL libraries.\n",
    "Modern neural network architectures can have millions of learnable parameters. From a computational point of view, training a neural network consists of two phases:\n",
    "\n",
    "- A forward pass to compute the value of the loss function.\n",
    "- A backward pass to compute the gradients of the learnable parameters.\n",
    "\n",
    "Very simple computational graph:\n",
    "\n",
    "<img src=\"https://blog.paperspace.com/content/images/2019/03/computation_graph_forward.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And its forward equations:\n",
    "\n",
    "$b = w1 * a $\n",
    "\n",
    "$c = w2 * a$\n",
    "\n",
    "$d = w3*b + w4*c$\n",
    "\n",
    "$L=10-d$\n",
    "\n",
    "and backward equations:\n",
    "\n",
    "$$\\frac{\\partial{L}}{\\partial{w_4}} = \\frac{\\partial{L}}{\\partial{d}} * \\frac{\\partial{d}}{\\partial{w_4}}$$\n",
    "\n",
    "$$\\frac{\\partial{L}}{\\partial{w_3}} = \\frac{\\partial{L}}{\\partial{d}} * \\frac{\\partial{d}}{\\partial{w_3}}$$\n",
    "\n",
    "$$\\frac{\\partial{L}}{\\partial{w_2}} = \\frac{\\partial{L}}{\\partial{d}} * \\frac{\\partial{d}}{\\partial{c}} * \\frac{\\partial{c}}{\\partial{w_2}}$$\n",
    "\n",
    "$$\\frac{\\partial{L}}{\\partial{w_1}} = \\frac{\\partial{L}}{\\partial{d}} * \\frac{\\partial{d}}{\\partial{b}} * \\frac{\\partial{b}}{\\partial{w_1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the computational graph for forward equations must be:\n",
    "    \n",
    "<img src=\"https://blog.paperspace.com/content/images/2019/03/computation_graph.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the computational graph for backward equations must be:\n",
    "    \n",
    "<img src=\"https://blog.paperspace.com/content/images/2019/03/full_graph.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see, the product is precisely the same expression we derived using chain rule. If there is more than one path to a variable from L then, we multiply the edges along each path and then add them together. For example, $\\frac{\\partial L}{\\partial a}$ is computed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{L}}{\\partial{a}} = \\frac{\\partial{L}}{\\partial{d}}*\\frac{\\partial{d}}{\\partial{b}}*\\frac{\\partial{b}}{\\partial{a}} + \\frac{\\partial{L}}{\\partial{d}}*\\frac{\\partial{d}}{\\partial{c}}*\\frac{\\partial{c}}{\\partial{a}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1491, -0.7433, -1.4484],\n",
      "        [ 0.3656,  0.8438,  0.4780],\n",
      "        [ 2.0702,  0.8685, -0.2250]], requires_grad=True)\n",
      "The grad fn for a is:  None\n",
      "The grad fn for d is:  <AddBackward0 object at 0x7f17e6b572b0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((3,3), requires_grad = True)\n",
    "w1 = torch.randn((3,3), requires_grad = True)\n",
    "print(w1)\n",
    "w2 = torch.randn((3,3), requires_grad = True)\n",
    "w3 = torch.randn((3,3), requires_grad = True)\n",
    "w4 = torch.randn((3,3), requires_grad = True)\n",
    "\n",
    "b = w1*a \n",
    "c = w2*a\n",
    "d = w3*b + w4*c \n",
    "L = 10 - d\n",
    "\n",
    "print(\"The grad fn for a is: \", a.grad_fn)\n",
    "print(\"The grad fn for d is: \", d.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "## L.backward() will give error\n",
    "#This is because gradients can be computed with respect to scalar values by definition.\n",
    "#You can't exactly differentiate a vector with respect to another vector. \n",
    "#The mathematical entity used for such cases is called a Jacobian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "L = (10-d).sum()\n",
    "L.backward()\n",
    "w1 = w1 - learning_rate * w1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1555, -0.7489, -1.4439],\n",
      "        [ 0.3755,  0.8516,  0.4825],\n",
      "        [ 2.0660,  0.8642, -0.2364]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good resoruce and reference for me: https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/\n",
    "check for more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
